<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>spark - 标签 - PME-Blog</title>
    <link>https://hpkaiq.github.io/tags/spark/</link>
    <description>spark - 标签 - PME-Blog</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>hpkaiq@qq.com (hpkaiq)</managingEditor>
      <webMaster>hpkaiq@qq.com (hpkaiq)</webMaster><lastBuildDate>Mon, 17 Apr 2023 21:29:55 &#43;0800</lastBuildDate><atom:link href="https://hpkaiq.github.io/tags/spark/" rel="self" type="application/rss+xml" /><item>
  <title>spark 读取 hive date 分区表 奇怪的报错</title>
  <link>https://hpkaiq.github.io/posts/spark-hive-partition-issue/</link>
  <pubDate>Mon, 17 Apr 2023 21:29:55 &#43;0800</pubDate>
  <author>hpkaiq</author>
  <guid>https://hpkaiq.github.io/posts/spark-hive-partition-issue/</guid>
  <description><![CDATA[<p>当 hive 表的分区字段 是 date 类型时，用如下方式读取会发生报错。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">val</span> <span class="n">targetDay</span> <span class="k">=</span> <span class="s">&#34;2020-08-20&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="o">(</span><span class="n">tableName</span><span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="s">s&#34;targetday in (&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,59),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,49),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,39),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,29),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,14),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,6),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,5),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,4),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,3),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,2),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,1),&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">      <span class="s">s&#34;date_sub(&#39;</span><span class="si">$targetDay</span><span class="s">&#39;,0))&#34;</span> <span class="o">).</span><span class="n">show</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>targetday 为 表的分区字段，date类型。
当 in 后面 的日期个数大于 10 时就会报错，小于等于 10 时都不会报错。奇怪的现象。。。
targetday 为 string 类型不会有此错误。</p>]]></description>
</item>
<item>
  <title>spark yarn cluster模式下log4j日志的配置</title>
  <link>https://hpkaiq.github.io/posts/spark-yarn-cluster-log4j/</link>
  <pubDate>Mon, 17 Apr 2023 21:19:43 &#43;0800</pubDate>
  <author>hpkaiq</author>
  <guid>https://hpkaiq.github.io/posts/spark-yarn-cluster-log4j/</guid>
  <description><![CDATA[<p>最近线上的spark项目日志文件急剧增加，磁盘顶不住了啊，解决日志文件问题，参考下面三篇文章，基本就可以搞明白了。</p>
<ol>
<li><a href="https://www.jianshu.com/p/0fe51185eeba"target="_blank" rel="external nofollow noopener noreferrer">Spark日志过大导致磁盘溢出问题解决方案<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="http://www.cnblogs.com/163yun/p/9882530.html"target="_blank" rel="external nofollow noopener noreferrer">Spark日志配置及问题排查方式。<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://blog.csdn.net/ZMC921/article/details/80238392"target="_blank" rel="external nofollow noopener noreferrer">Spark log4j 日志配置详解<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ol>
<p>以上内容转载自网络，如有侵权，请联系删除。</p>]]></description>
</item>
</channel>
</rss>
