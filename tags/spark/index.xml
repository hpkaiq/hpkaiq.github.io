<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spark - 标签 - PME-Blog</title><link>https://hpk.me/tags/spark/</link><description>PME-Blog 难得自在</description><generator>Hugo 0.147.9 &amp; FixIt v0.3.21-b2e6f70a</generator><language>zh-CN</language><lastBuildDate>Wed, 25 Jun 2025 00:42:43 +0800</lastBuildDate><atom:link href="https://hpk.me/tags/spark/index.xml" rel="self" type="application/rss+xml"/><item><title>Spark通过Jdbc读取Doris varchar类型长度异常</title><link>https://hpk.me/posts/394428b/</link><pubDate>Wed, 25 Jun 2025 00:27:44 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/394428b/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>spark内通过jdbc方式读取doris数据，varchar类型长度不足85时总是自动填充空格至85长度。&lt;/p></description></item><item><title>spark 实现 mysql upsert，可忽略null值</title><link>https://hpk.me/posts/spark-mysql-upsert/</link><pubDate>Tue, 18 Apr 2023 14:23:06 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/spark-mysql-upsert/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>&lt;strong>实现 spark dataframe/dataset 根据mysql表唯一键实现有则更新，无则插入功能。&lt;/strong>&lt;/p>
&lt;p>&lt;strong>2024.07.25更新：新增特性，忽略值为null的列，即当df里列值为null时，不更新mysql表数据，保留表原有的值。&lt;/strong>&lt;/p></description></item><item><title>脚本执行spark-shell scala文件退出</title><link>https://hpk.me/posts/bash-spark-shell-scala/</link><pubDate>Tue, 18 Apr 2023 14:09:10 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/bash-spark-shell-scala/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>脚本执行spark-shell scala文件退出</description></item><item><title>spark 读取 hive date 分区表 奇怪的报错</title><link>https://hpk.me/posts/spark-hive-partition-issue/</link><pubDate>Mon, 17 Apr 2023 21:29:55 +0800</pubDate><guid>https://hpk.me/posts/spark-hive-partition-issue/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>spark 读取 hive date 分区表 奇怪的报错</description></item><item><title>spark yarn cluster模式下log4j日志的配置</title><link>https://hpk.me/posts/spark-yarn-cluster-log4j/</link><pubDate>Mon, 17 Apr 2023 21:19:43 +0800</pubDate><guid>https://hpk.me/posts/spark-yarn-cluster-log4j/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>spark yarn cluster模式下log4j日志的配置</description></item></channel></rss>