<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>大数据 - 标签 - PME-Blog</title><link>https://hpk.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link><description>PME-Blog 难得自在</description><generator>Hugo 0.139.4 &amp; FixIt v0.3.16</generator><language>zh-CN</language><lastBuildDate>Thu, 12 Dec 2024 14:50:25 +0800</lastBuildDate><atom:link href="https://hpk.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml"/><item><title>hive 日期维度表</title><link>https://hpk.me/posts/hive-dim-date/</link><pubDate>Thu, 12 Dec 2024 11:38:59 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/hive-dim-date/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>hive日期维度表，常用的字段基本都有。&lt;/p></description></item><item><title>spark 实现 mysql upsert，可忽略null值</title><link>https://hpk.me/posts/spark-mysql-upsert/</link><pubDate>Tue, 18 Apr 2023 14:23:06 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/spark-mysql-upsert/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>&lt;strong>实现 spark dataframe/dataset 根据mysql表唯一键实现有则更新，无则插入功能。&lt;/strong>&lt;/p>
&lt;p>&lt;strong>2024.07.25更新：新增特性，忽略值为null的列，即当df里列值为null时，不更新mysql表数据，保留表原有的值。&lt;/strong>&lt;/p></description></item><item><title>presto 自定义函数简述</title><link>https://hpk.me/posts/presto-udf-simple/</link><pubDate>Tue, 18 Apr 2023 14:16:42 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/presto-udf-simple/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>presto自带unbase64函数某些时候会报错，所以想要自定义一个unbase64函数。&lt;/p></description></item><item><title>sqoop mysql update AUTO_INCREMENT 自增主键重复增长问题</title><link>https://hpk.me/posts/sqoop-mysql-update-auto-increment/</link><pubDate>Tue, 18 Apr 2023 14:11:19 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/sqoop-mysql-update-auto-increment/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>sqoop mysql update AUTO_INCREMENT 自增主键重复增长问题</description></item><item><title>脚本执行spark-shell scala文件退出</title><link>https://hpk.me/posts/bash-spark-shell-scala/</link><pubDate>Tue, 18 Apr 2023 14:09:10 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/bash-spark-shell-scala/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>脚本执行spark-shell scala文件退出</description></item><item><title>kudu-spark KuduContext java.io.InvalidClassException 解决</title><link>https://hpk.me/posts/kudu-spark-invalid-class-exception/</link><pubDate>Tue, 18 Apr 2023 13:56:34 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/kudu-spark-invalid-class-exception/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>背景：
线上kudu 集群版本为1.11.0版本, spark 使用 kudu-spark2_2.11-1.7.0.jar，
为了使用新版本中的
&lt;code>val wo = new KuduWriteOptions(ignoreNull = true)&lt;/code>
特性，升级至 kudu-spark2_2.11-1.11.0.jar 版本，但是报错。&lt;/p></description></item><item><title>phoenix-client-4.14.1-HBase-1.4.jar jar包冲突解决</title><link>https://hpk.me/posts/phoenix-client-hbase-jar/</link><pubDate>Tue, 18 Apr 2023 13:49:28 +0800</pubDate><guid>https://hpk.me/posts/phoenix-client-hbase-jar/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>项目用到phoenix，使用了这个jar包phoenix-client-4.14.1-HBase-1.4.jar，这个jar包导致的jar包冲突很多，一番摸索，解决了，解决如下。&lt;/p></description></item><item><title>spark 读取 hive date 分区表 奇怪的报错</title><link>https://hpk.me/posts/spark-hive-partition-issue/</link><pubDate>Mon, 17 Apr 2023 21:29:55 +0800</pubDate><guid>https://hpk.me/posts/spark-hive-partition-issue/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>spark 读取 hive date 分区表 奇怪的报错</description></item><item><title>Apache Kudu 写入数据定期出问题</title><link>https://hpk.me/posts/kudu-periodic-issues/</link><pubDate>Mon, 17 Apr 2023 21:23:09 +0800</pubDate><guid>https://hpk.me/posts/kudu-periodic-issues/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>Apache Kudu 写入数据定期出问题</description></item><item><title>spark yarn cluster模式下log4j日志的配置</title><link>https://hpk.me/posts/spark-yarn-cluster-log4j/</link><pubDate>Mon, 17 Apr 2023 21:19:43 +0800</pubDate><guid>https://hpk.me/posts/spark-yarn-cluster-log4j/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>spark yarn cluster模式下log4j日志的配置</description></item></channel></rss>