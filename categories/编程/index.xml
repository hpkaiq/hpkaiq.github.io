<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>编程 - 分类 - PME-Blog</title><link>https://hpk.me/categories/%E7%BC%96%E7%A8%8B/</link><description>PME-Blog 难得自在</description><generator>Hugo 0.147.9 &amp; FixIt v0.3.21-b2e6f70a</generator><language>zh-CN</language><lastBuildDate>Wed, 25 Jun 2025 00:42:43 +0800</lastBuildDate><atom:link href="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>Spark通过Jdbc读取Doris varchar类型长度异常</title><link>https://hpk.me/posts/394428b/</link><pubDate>Wed, 25 Jun 2025 00:27:44 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/394428b/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>spark内通过jdbc方式读取doris数据，varchar类型长度不足85时总是自动填充空格至85长度。&lt;/p></description></item><item><title>hive 日期维度表</title><link>https://hpk.me/posts/hive-dim-date/</link><pubDate>Thu, 12 Dec 2024 11:38:59 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/hive-dim-date/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>hive日期维度表，常用的字段基本都有。&lt;/p></description></item><item><title>spark 实现 mysql upsert，可忽略null值</title><link>https://hpk.me/posts/spark-mysql-upsert/</link><pubDate>Tue, 18 Apr 2023 14:23:06 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/spark-mysql-upsert/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>&lt;strong>实现 spark dataframe/dataset 根据mysql表唯一键实现有则更新，无则插入功能。&lt;/strong>&lt;/p>
&lt;p>&lt;strong>2024.07.25更新：新增特性，忽略值为null的列，即当df里列值为null时，不更新mysql表数据，保留表原有的值。&lt;/strong>&lt;/p></description></item><item><title>java 频次控制</title><link>https://hpk.me/posts/java-rate-limit-google-guava/</link><pubDate>Tue, 18 Apr 2023 14:21:15 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/java-rate-limit-google-guava/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>访问某接口拉取数据，接口需要频次控制，经调研，&lt;code>com.google.common.util.concurrent.RateLimiter&lt;/code>可轻易实现。&lt;/p></description></item><item><title>python3 easyocr 简单使用识别参数</title><link>https://hpk.me/posts/python3-easyocr-simple/</link><pubDate>Tue, 18 Apr 2023 14:18:37 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/python3-easyocr-simple/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>python3 easyocr 学习，测试。&lt;/p></description></item><item><title>presto 自定义函数简述</title><link>https://hpk.me/posts/presto-udf-simple/</link><pubDate>Tue, 18 Apr 2023 14:16:42 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/presto-udf-simple/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>presto自带unbase64函数某些时候会报错，所以想要自定义一个unbase64函数。&lt;/p></description></item><item><title>python3 pandas 实现mysql upsert操作（唯一键更新）</title><link>https://hpk.me/posts/python3-pandas-mysql-upsert/</link><pubDate>Tue, 18 Apr 2023 14:15:04 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/python3-pandas-mysql-upsert/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>python3 pandas 实现mysql upsert操作，基于唯一键有则更新，无则插入。&lt;/p></description></item><item><title>sqoop mysql update AUTO_INCREMENT 自增主键重复增长问题</title><link>https://hpk.me/posts/sqoop-mysql-update-auto-increment/</link><pubDate>Tue, 18 Apr 2023 14:11:19 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/sqoop-mysql-update-auto-increment/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>sqoop mysql update AUTO_INCREMENT 自增主键重复增长问题</description></item><item><title>脚本执行spark-shell scala文件退出</title><link>https://hpk.me/posts/bash-spark-shell-scala/</link><pubDate>Tue, 18 Apr 2023 14:09:10 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/bash-spark-shell-scala/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>脚本执行spark-shell scala文件退出</description></item><item><title>kudu-spark KuduContext java.io.InvalidClassException 解决</title><link>https://hpk.me/posts/kudu-spark-invalid-class-exception/</link><pubDate>Tue, 18 Apr 2023 13:56:34 +0800</pubDate><author>hpkaiq@qq.com (hpkaiq)</author><guid>https://hpk.me/posts/kudu-spark-invalid-class-exception/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>背景：
线上kudu 集群版本为1.11.0版本, spark 使用 kudu-spark2_2.11-1.7.0.jar，
为了使用新版本中的
&lt;code>val wo = new KuduWriteOptions(ignoreNull = true)&lt;/code>
特性，升级至 kudu-spark2_2.11-1.11.0.jar 版本，但是报错。&lt;/p></description></item><item><title>phoenix-client-4.14.1-HBase-1.4.jar jar包冲突解决</title><link>https://hpk.me/posts/phoenix-client-hbase-jar/</link><pubDate>Tue, 18 Apr 2023 13:49:28 +0800</pubDate><guid>https://hpk.me/posts/phoenix-client-hbase-jar/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>项目用到phoenix，使用了这个jar包phoenix-client-4.14.1-HBase-1.4.jar，这个jar包导致的jar包冲突很多，一番摸索，解决了，解决如下。&lt;/p></description></item><item><title>spark 读取 hive date 分区表 奇怪的报错</title><link>https://hpk.me/posts/spark-hive-partition-issue/</link><pubDate>Mon, 17 Apr 2023 21:29:55 +0800</pubDate><guid>https://hpk.me/posts/spark-hive-partition-issue/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>spark 读取 hive date 分区表 奇怪的报错</description></item><item><title>Apache Kudu 写入数据定期出问题</title><link>https://hpk.me/posts/kudu-periodic-issues/</link><pubDate>Mon, 17 Apr 2023 21:23:09 +0800</pubDate><guid>https://hpk.me/posts/kudu-periodic-issues/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>Apache Kudu 写入数据定期出问题</description></item><item><title>spark yarn cluster模式下log4j日志的配置</title><link>https://hpk.me/posts/spark-yarn-cluster-log4j/</link><pubDate>Mon, 17 Apr 2023 21:19:43 +0800</pubDate><guid>https://hpk.me/posts/spark-yarn-cluster-log4j/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>spark yarn cluster模式下log4j日志的配置</description></item><item><title>阿里Druid连接池连接不释放、连接泄漏排查</title><link>https://hpk.me/posts/druid-connect-not-free/</link><pubDate>Mon, 17 Apr 2023 21:12:25 +0800</pubDate><guid>https://hpk.me/posts/druid-connect-not-free/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>阿里Druid连接池连接不释放、连接泄漏排查</description></item><item><title>spring cloud java反向代理访问阿里云OSS私有资源</title><link>https://hpk.me/posts/spring-proxy-oss/</link><pubDate>Mon, 17 Apr 2023 20:43:10 +0800</pubDate><guid>https://hpk.me/posts/spring-proxy-oss/</guid><category domain="https://hpk.me/categories/%E7%BC%96%E7%A8%8B/">编程</category><description>&lt;p>最近用到阿里云oss，有阿里云服务器，通过代理内网访问可以实现免除OSS流量费，查到很多nginx反向代理的教程，但是纯java实现没有找到，感觉可以试一试。&lt;/p></description></item></channel></rss>